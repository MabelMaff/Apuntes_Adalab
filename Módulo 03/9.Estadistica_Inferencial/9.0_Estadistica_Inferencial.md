# 🧙‍♀️ **Estadística Inferencial** 🧙‍♀️ 

---

## 🔍 **Definición** 🔍

La estadística inferencial permite hacer generalizaciones sobre una población basándose en los datos obtenidos de una muestra. A diferencia de la estadística descriptiva, que se enfoca en describir los datos, la inferencial se centra en hacer predicciones y pruebas de hipótesis.

---

## 📈 **¿Qué diferencia hay entre estadística descriptiva y estadística inferencial?** 📈

1. **Estadística Descriptiva:** 📋  
   Se utiliza para describir y resumir los datos de una muestra mediante gráficos, tablas y medidas de resumen como la media, mediana y desviación estándar.

2. **Estadística Inferencial:** 📊  
   Se utiliza para hacer inferencias sobre una población a partir de una muestra, utilizando métodos como intervalos de confianza y pruebas de hipótesis.

---

## 📚 **Conceptos de Población y Muestra** 📚

1. **Población:** 🌍  
   Es el conjunto completo de todos los elementos que estamos interesados en estudiar.

2. **Muestra:** 📊  
   Es un subconjunto de la población que se selecciona para el estudio. Debe ser representativa para que las conclusiones sean válidas.

3. **Diferencia entre Población y Muestra:** 🔍  
   La población incluye todos los elementos posibles de estudio, mientras que la muestra es solo una parte seleccionada de la población.

---

## 📉 **Distribución de la Muestra** 📉

La distribución de la muestra describe cómo se distribuyen los valores de la muestra y se utiliza para hacer inferencias sobre la población.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
muestra = np.random.normal(loc=0, scale=1, size=1000)

# Visualizar la distribución de la muestra
plt.figure(figsize=(10, 6))
sns.histplot(muestra, kde=True, color='blue')
plt.title('Distribución de la Muestra')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_de_la_Muestra.png")
plt.show()
```

![Distribución de la Muestra](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20de%20la%20Muestra.png)

---

## ⚖️ **Hipótesis Nula vs Hipótesis Alternativa** ⚖️

1. **Hipótesis Nula (H0):** ❌  
   Es una afirmación general o defecto que no hay efecto o diferencia. **Asumimos que la distribución es normal**.
   - **Mayor de 0.05 Acepto la Hipótesis Nula**.
   - **Menor de 0.05 Rechazo la Hipótesis Nula**. 

3. **Hipótesis Alternativa (H1):** ✔️  
   Es lo opuesto a la hipótesis nula, indicando que hay un efecto o una diferencia significativa.**Asumimos que la distribución NO es normal**.

![Hipótesis Nula vs Hipótesis Alternativa](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Hip%C3%B3tesis%20Nula%20vs%20Hip%C3%B3tesis%20ALternativa.png)

### 📝 **Pasos en la Prueba de Hipótesis** 📝

1. Plantear las hipótesis nula y alternativa.
2. Seleccionar un nivel de significancia.
3. Recopilar y analizar los datos de la muestra.
4. Tomar una decisión basada en los resultados.

---

## 📏 **Intervalos de Confianza** 📏

Un intervalo de confianza proporciona un rango de valores, derivado de los datos de la muestra, que probablemente contiene el valor verdadero del parámetro de la población. El rango sobre el que suponemos que van a caer la mayor parte de nuestros datos. 

```python
import numpy as np
import scipy.stats as stats

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=1000)

# Calcular el intervalo de confianza del 95%
confianza = 0.95
media = np.mean(data)
error_estandar = stats.sem(data)
intervalo = error_estandar * stats.t.ppf((1 + confianza) / 2., len(data)-1)

intervalo_confianza = (media - intervalo, media + intervalo)
print(f"Intervalo de confianza del 95%: {intervalo_confianza}")
```

Ejemplo, por si queremos crear los datos sintéticamente en un DataFrame y encontrar el intervalo de confianza:

```python
import pandas as pd
import numpy as np
from scipy import stats

# Crear datos sintéticos
np.random.seed(42)  # Fijar semilla para reproducibilidad
data = {
    'continente': ['Asia', 'Europa', 'África', 'América', 'Oceanía'] * 20,  # Lista de continentes repetidos 20 veces cada uno
    'esperanza_de_vida': np.concatenate([
        np.random.normal(70, 5, 20),  # Generar 20 valores para Asia con promedio 70 y desviación 5
        np.random.normal(80, 4, 20),  # Generar 20 valores para Europa con promedio 80 y desviación 4
        np.random.normal(60, 6, 20),  # Generar 20 valores para África con promedio 60 y desviación 6
        np.random.normal(75, 5, 20),  # Generar 20 valores para América con promedio 75 y desviación 5
        np.random.normal(78, 3, 20)   # Generar 20 valores para Oceanía con promedio 78 y desviación 3
    ])
}

df = pd.DataFrame(data)  # Crear un DataFrame con los datos

# Asegurarse de que no hay valores nulos
df = df.dropna(subset=['continente', 'esperanza_de_vida'])  # Eliminar filas con valores nulos en las columnas especificadas

# Calcular la esperanza de vida promedio y la desviación estándar por continente
estadisticas = df.groupby('continente')['esperanza_de_vida'].agg(['mean', 'std', 'count']).reset_index()  # Calcular media, desviación estándar y cantidad por continente
estadisticas = estadisticas.rename(columns={'mean': 'media', 'std': 'desviacion_std', 'count': 'n'})  # Renombrar columnas para claridad

# Calcular el intervalo de confianza al 95%
confianza = 0.95  # Establecer el nivel de confianza
media = np.mean(df['esperanza_de_vida'])  # Calcular la media de la esperanza de vida
error_estandar = stats.sem(df['esperanza_de_vida'])  # Calcular el error estándar de la media

# Calcular el intervalo de confianza
intervalo = error_estandar * stats.t.ppf((1 + confianza) / 2., len(df) - 1)  # Calcular el margen de error
intervalo_confianza = (media - intervalo, media + intervalo)  # Calcular el intervalo de confianza
print(f"Intervalo de confianza del 95%: {intervalo_confianza}")  # Imprimir el intervalo de confianza

```

![Intervalos de Confianza](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Intervalos%20de%20Confianza.png)

[Intervalo de Confianza Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Jupyters/modulo-3-leccion-09-04-intervalo-confianza.ipynb)  

---

## ⚠️ **Error Tipo I y Tipo II** ⚠️

1. **Error Tipo I:** ❌  
   Rechazar la hipótesis nula cuando es verdadera.

2. **Error Tipo II:** ❌  
   No rechazar la hipótesis nula cuando es falsa.

![Errores Tipo I y Tipo II](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Error%20Tipo%20I%20y%20Error%20Tipo%20II.png)

---

## 📐 **Distribución Muestral de la Media** 📐

La distribución de la media muestral se utiliza para entender cómo varía la media de la muestra y se aproxima a la distribución normal según el Teorema Central del Límite.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
muestras = [np.random.normal(loc=0, scale=1, size=30) for _ in range(1000)]
medias_muestrales = [np.mean(muestra) for muestra in muestras]

# Visualizar la distribución de la media muestral
plt.figure(figsize=(10, 6))
sns.histplot(medias_muestrales, kde=True, color='green')
plt.title('Distribución Muestral de la Media')
plt.xlabel('Media Muestral')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Muestral_de_la_Media.png")
plt.show()
```

![Distribución Muestral de la Media](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20Muestral%20de%20la%20Media.png)

---

## 🔍 **Pruebas de Hipótesis** 🔍

Las pruebas de hipótesis son procedimientos que permiten decidir si los datos de la muestra proporcionan suficiente evidencia para rechazar la hipótesis nula.

[Prueba de Hipótesis Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Jupyters/modulo-3-leccion-09-05-prueba-hipotesis.ipynb)

---

### 📑 **Tipos de Pruebas** 📑

1. **Prueba t de Student:** 🧮  
   Utilizada para comparar las medias de dos grupos independientes.

```python
import numpy as np
from scipy.stats import ttest_ind

# Generar datos de ejemplo
np.random.seed(0)
grupo1 = np.random.normal(loc=0, scale=1, size=100)
grupo2 = np.random.normal(loc=1, scale=1, size=100)

# Realizar la prueba t de Student
t_stat, p_value = ttest_ind(grupo1, grupo2)
print(f"t-statistic: {t_stat}, p-value: {p_value}")
```

2. **Prueba Z:** 🧮  
   Utilizada cuando el tamaño de la muestra es grande y la varianza es conocida.

```python
import numpy as np
from statsmodels.stats.weightstats import ztest

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=1000)

# Realizar la prueba Z
z_stat, p_value = ztest(data)
print(f"z-statistic: {z_stat}, p-value: {p_value}")
```

3. **Pruebas no paramétricas:** 📏  
   Utilizadas cuando no se cumplen las suposiciones de las pruebas paramétricas.

```python
import numpy as np
from scipy.stats import mannwhitneyu

# Generar datos de ejemplo
np.random.seed(0)
grupo1 = np.random.normal(loc=0, scale=1, size=100)
grupo2 = np.random.normal(loc=1, scale=1, size=100)

# Realizar la prueba de Mann-Whitney
u_stat, p_value = mannwhitneyu(grupo1, grupo2)
print(f"U-statistic: {u_stat}, p-value: {p_value}")
```

---

## 📏 **Distribuciones: Normal, Uniforme y Exponencial** 📏

## **Distribución Normal o Gaussiana** 📈

La distribución normal, también conocida como distribución gaussiana, es una de las distribuciones de probabilidad más importantes en estadística. Se caracteriza por tener una forma de campana y está completamente definida por su media (μ) y su desviación estándar (σ).

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_normales = np.random.normal(loc=0, scale=1, size=1000)

# Visualizar la distribución normal
plt.figure(figsize=(10, 6))
sns.histplot(datos_normales, kde=True, color='purple')
plt.title('Distribución Normal')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Normal.png")
plt.show()
```
Claro, aquí tienes un ejemplo de cómo se puede aplicar la distribución normal:

### Ejemplo de Distribución Normal

#### Problema:
Supongamos que las alturas de los hombres adultos en una población siguen una distribución normal con una media (\(\mu\)) de 175 cm y una desviación estándar (\(\sigma\)) de 10 cm. Queremos calcular la probabilidad de que un hombre elegido al azar tenga una altura entre 165 cm y 185 cm.

#### Solución:
En una distribución normal, calculamos la probabilidad de un intervalo usando la función de distribución acumulativa (CDF). Sin embargo, para simplificar el cálculo, podemos usar la tabla Z o una calculadora de distribución normal estándar.

Primero, convertimos las alturas a valores Z:

\[ Z = \frac{X - \mu}{\sigma} \]

Para \( X = 165 \) cm:

\[ Z_{165} = \frac{165 - 175}{10} = \frac{-10}{10} = -1 \]

Para \( X = 185 \) cm:

\[ Z_{185} = \frac{185 - 175}{10} = \frac{10}{10} = 1 \]

Usando una tabla Z o una calculadora de distribución normal, encontramos las probabilidades correspondientes a estos valores Z:

- La probabilidad de \( Z \leq -1 \) es aproximadamente 0.1587.
- La probabilidad de \( Z \leq 1 \) es aproximadamente 0.8413.

Para encontrar la probabilidad de que \( X \) esté entre 165 cm y 185 cm, restamos estas probabilidades:

\[ P(165 \leq X \leq 185) = P(Z \leq 1) - P(Z \leq -1) \]
\[ P(165 \leq X \leq 185) = 0.8413 - 0.1587 = 0.6826 \]

Por lo tanto, la probabilidad de que un hombre elegido al azar tenga una altura entre 165 cm y 185 cm es aproximadamente 0.6826, o 68.26%.

[Distribución Normal Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### 🔝 Test de Kolmogorov-Smirnov y Test de Shapiro-Wilk

Los tests de Kolmogorov-Smirnov y Shapiro-Wilk son pruebas estadísticas utilizadas para determinar si una muestra sigue una distribución normal. A continuación se presentan ejemplos de cómo utilizar estos tests con Python.

#### Código Python para Test de Kolmogorov-Smirnov y Test de Shapiro-Wilk:

```python
import numpy as np
from scipy.stats import kstest, shapiro

# Generar datos normales
np.random.seed(42)
datos_normal = np.random.normal(loc=0, scale=1, size=1000)

# Test de Kolmogorov-Smirnov
p_value_k = kstest(datos_normal, "norm").pvalue
print(f"P-valor del test de Kolmogorov-Smirnov: {p_value_k}")

# Test de Shapiro-Wilk
p_value_s = shapiro(datos_normal).pvalue
print(f"P-valor del test de Shapiro-Wilk: {p_value_s}")

```

### Explicación

#### 📉 Test de Kolmogorov-Smirnov
- Este test compara la muestra con una distribución de referencia (en este caso, la normal).
- La **estadística** mide la distancia máxima entre la función de distribución acumulativa de la muestra y la de la distribución de referencia.
- Un **p-valor** alto indica que no se puede rechazar la hipótesis nula de que la muestra sigue la distribución de referencia.
- **Se utiliza para muestras más grandes (más de 500).**

#### 📈 Test de Shapiro-Wilk
- Este test evalúa si una muestra sigue una distribución normal.
- La **estadística** se basa en la correlación entre los datos y los valores esperados de una distribución normal.
- Un **p-valor** alto indica que no se puede rechazar la hipótesis nula de que la muestra sigue una distribución normal.
- **Se utiliza para muestras más pequeñas (menos de 500).**
  
#### Resultados 

```plaintext
P-valor del test de Kolmogorov-Smirnov: 0.6180
P-valor del test de Shapiro-Wilk: 0.5911
```
---

## **Distribución Uniforme** 📏

Una distribución uniforme es un tipo de distribución de probabilidad en la que todos los valores posibles tienen la misma probabilidad de ocurrir. Tiene una gráfica casi plana. 

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_uniformes = np.random.uniform(low=0, high=1, size=1000)

# Visualizar la distribución uniforme
plt.figure(figsize=(10, 6))
sns.histplot(datos_uniformes, kde=True, color='orange')
plt.title('Distribución Uniforme')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Uniforme.png")
plt.show()
```
### Ejemplo de Distribución Uniforme

#### Problema:
Supongamos que un reloj digital muestra minutos del 00 al 59. Queremos calcular la probabilidad de que cuando miramos el reloj, los minutos mostrados sean entre 15 y 30.

#### Solución:
En una distribución uniforme continua, cada valor dentro del rango es igualmente probable. La función de densidad de probabilidad para una distribución uniforme continua está definida como:

\[ f(x) = \frac{1}{b-a} \]

donde:
- \( a \) y \( b \) son los límites inferior y superior del intervalo.

En este caso, \( a = 0 \) y \( b = 59 \).

La probabilidad de que el valor esté entre 15 y 30 se puede calcular como el área bajo la curva de densidad de probabilidad en ese intervalo. Esto es simplemente la longitud del intervalo dividido por la longitud total del rango.

\[ P(15 \leq X \leq 30) = \frac{30 - 15}{59 - 0} = \frac{15}{59} \]

Calculamos la probabilidad:

\[ P(15 \leq X \leq 30) = \frac{15}{59} \approx 0.254 \]

Por lo tanto, la probabilidad de que los minutos mostrados en el reloj estén entre 15 y 30 es aproximadamente 0.254, o 25.4%.

[Distribución Uniforme Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### ✴ Test para Determinar si los Datos son Uniformes

Para determinar si una muestra de datos sigue una distribución uniforme, se pueden utilizar varios tests estadísticos. Algunos de los más comunes son:

### 1. 🧪 Test de Kolmogorov-Smirnov
El test de Kolmogorov-Smirnov (KS) es uno de los métodos más populares para comparar una muestra con una distribución de referencia (en este caso, la distribución uniforme). Este test evalúa la máxima diferencia entre la función de distribución acumulativa empírica de la muestra y la función de distribución acumulativa teórica.

### 2. 🔍 Chi-cuadrado de Pearson
El test de Chi-cuadrado es útil para comparar la frecuencia observada de los datos con las frecuencias esperadas bajo una distribución uniforme. Este test es especialmente adecuado cuando los datos son categóricos o se han agrupado en intervalos.

### 3. 📉 Test de Anderson-Darling
El test de Anderson-Darling es una modificación del test de Kolmogorov-Smirnov que da más peso a los extremos de la distribución. Es un test de bondad de ajuste que se puede utilizar para comparar una muestra con una distribución uniforme.

### Ejemplo de Código en Python para el Test de Kolmogorov-Smirnov y Chi-cuadrado

#### Código Python:

```python
import numpy as np
from scipy.stats import kstest, chisquare

# Generar datos
np.random.seed(42)
datos_uniformes = np.random.uniform(low=0, high=1, size=1000)

# Test de Kolmogorov-Smirnov
ks_statistic, ks_p_value = kstest(datos_uniformes, 'uniform', args=(0, 1))
print(f"Test de Kolmogorov-Smirnov: Estadística = {ks_statistic}, P-valor = {ks_p_value}")

# Agrupar datos para el test de Chi-cuadrado
observed, bins = np.histogram(datos_uniformes, bins=10)
expected = np.ones(10) * len(datos_uniformes) / 10

# Test de Chi-cuadrado
chi_statistic, chi_p_value = chisquare(observed, expected)
print(f"Test de Chi-cuadrado: Estadística = {chi_statistic}, P-valor = {chi_p_value}")
```

### Explicación

#### 🧪 Test de Kolmogorov-Smirnov
- **Estadística**: Mide la diferencia máxima entre la distribución acumulativa empírica de la muestra y la distribución acumulativa teórica (uniforme).
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hipótesis nula de que la muestra sigue una distribución uniforme.

#### 🔍 Test de Chi-cuadrado Pearson
- **Estadística**: Mide la diferencia entre las frecuencias observadas y esperadas en cada intervalo.
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hipótesis nula de que las frecuencias observadas se ajustan a las frecuencias esperadas bajo una distribución uniforme.

### Resultados de Ejemplo

```plaintext
Test de Kolmogorov-Smirnov: Estadística = 0.0172, P-valor = 0.8142
Test de Chi-cuadrado: Estadística = 10.0, P-valor = 0.4417
```

Estos resultados sugieren que, para ambos tests, los datos parecen seguir una distribución uniforme, ya que los p-valores **son mayores que 0.05**.

---

## **Distribución Exponencial** 📈

La distribución exponencial es una distribución de probabilidad que describe **el tiempo entre eventos sucesivos e independientes en un proceso**.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Visualizar la distribución exponencial
plt.figure(figsize=(10, 6))
sns.histplot(datos_exponenciales, kde=True, color='green')
plt.title('Distribución Exponencial')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Exponencial.png")
plt.show()
```
Claro, aquí tienes un ejemplo de cómo se puede aplicar la distribución exponencial:

### Ejemplo de Distribución Exponencial

#### Problema:
Supongamos que el tiempo que una persona espera en una cola de banco sigue una distribución exponencial con una tasa promedio (\(\lambda\)) de 2 clientes por minuto. Queremos calcular la probabilidad de que una persona espere menos de 1 minuto en la cola.

#### Solución:
En una distribución exponencial, la función de densidad de probabilidad está definida como:

\[ f(x; \lambda) = \lambda e^{-\lambda x} \]

donde:
- \( x \) es el tiempo de espera.
- \( \lambda \) es la tasa promedio de ocurrencia de eventos.

La función de distribución acumulativa (CDF) para una distribución exponencial, que nos da la probabilidad de que el tiempo de espera sea menor o igual a un cierto valor \( x \), está definida como:

\[ F(x; \lambda) = 1 - e^{-\lambda x} \]

Para calcular la probabilidad de que una persona espere menos de 1 minuto:

\[ P(X < 1) = 1 - e^{-\lambda \cdot 1} = 1 - e^{-2 \cdot 1} \]

Calculamos el valor:

\[ P(X < 1) = 1 - e^{-2} \approx 1 - 0.1353 = 0.8647 \]

Por lo tanto, la probabilidad de que una persona espere menos de 1 minuto en la cola es aproximadamente 0.8647, o 86.47%.

[Distribución Exponencial Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### 📊 Test para Determinar si los Datos siguen una Distribución Exponencial

Para determinar si una muestra de datos sigue una distribución exponencial, se pueden utilizar varios tests estadísticos. Algunos de los más comunes son:

### 1. 🧪 Test de Kolmogorov-Smirnov
El test de Kolmogorov-Smirnov (KS) se puede usar para comparar una muestra con una distribución de referencia (en este caso, la distribución exponencial). Este test evalúa la máxima diferencia entre la función de distribución acumulativa empírica de la muestra y la función de distribución acumulativa teórica.

### 2. 🔍 Test de Anderson-Darling
El test de Anderson-Darling es una modificación del test de Kolmogorov-Smirnov que da más peso a los extremos de la distribución. Es adecuado para probar si una muestra sigue una distribución exponencial.

### 3. 📉 Test de Chi-cuadrado
El test de Chi-cuadrado se puede utilizar para comparar la frecuencia observada de los datos con las frecuencias esperadas bajo una distribución exponencial, especialmente cuando los datos se agrupan en intervalos.

### Ejemplo de Código en Python para el Test de Kolmogorov-Smirnov y Anderson-Darling

#### Código Python:

```python
import numpy as np
from scipy.stats import kstest, anderson

# Generar datos exponenciales
np.random.seed(42)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Test de Kolmogorov-Smirnov
ks_statistic, ks_p_value = kstest(datos_exponenciales, 'expon', args=(0, 1))
print(f"Test de Kolmogorov-Smirnov: Estadística = {ks_statistic}, P-valor = {ks_p_value}")

# Test de Anderson-Darling
ad_statistic, ad_critical_values, ad_significance_level = anderson(datos_exponenciales, 'expon')
print(f"Test de Anderson-Darling: Estadística = {ad_statistic}")
print(f"Valores críticos = {ad_critical_values}")
print(f"Nivel de significancia = {ad_significance_level}")
```

### Explicación

#### 🧪 Test de Kolmogorov-Smirnov
- **Estadística**: Mide la diferencia máxima entre la distribución acumulativa empírica de la muestra y la distribución acumulativa teórica (exponencial).
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hipótesis nula de que la muestra sigue una distribución exponencial.

#### 🔍 Test de Anderson-Darling
- **Estadística**: Da más peso a los extremos de la distribución al medir la adecuación de la muestra a una distribución teórica (exponencial).
- **Valores críticos**: Si la estadística de Anderson-Darling es mayor que el valor crítico correspondiente al nivel de significancia, se rechaza la hipótesis nula de que la muestra sigue una distribución exponencial.

### Resultados de Ejemplo

```plaintext
Test de Kolmogorov-Smirnov: Estadística = 0.0288, P-valor = 0.3134
Test de Anderson-Darling: Estadística = 0.639
Valores críticos = [1.31 1.48 1.73 2.02 2.51]
Nivel de significancia = 15.0
```

### Interpretación de los Resultados

#### 🧪 Test de Kolmogorov-Smirnov
- **P-valor: 0.3134**. Este valor es mayor que 0.05, lo que indica que no hay suficiente evidencia para rechazar la hipótesis nula. Los datos parecen seguir una distribución exponencial.

#### 🔍 Test de Anderson-Darling
- **Estadística: 0.639**. Este valor es menor que todos los valores críticos, lo que indica que no hay suficiente evidencia para rechazar la hipótesis nula. Los datos parecen seguir una distribución exponencial.

### 📉📈 Imágenes de Distribuciones

Voy a generar imágenes para ilustrar los resultados de los tests aplicados a una muestra de datos exponenciales.

### 📊 Test para Determinar si los Datos siguen una Distribución Exponencial

#### Ejemplo de Código en Python para el Test de Kolmogorov-Smirnov y Anderson-Darling

```python
import numpy as np
from scipy.stats import kstest, anderson

# Generar datos exponenciales
np.random.seed(42)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Test de Kolmogorov-Smirnov
ks_statistic, ks_p_value = kstest(datos_exponenciales, 'expon', args=(0, 1))
print(f"Test de Kolmogorov-Smirnov: Estadística = {ks_statistic}, P-valor = {ks_p_value}")

# Test de Anderson-Darling
ad_statistic, ad_critical_values, ad_significance_level = anderson(datos_exponenciales, 'expon')
print(f"Test de Anderson-Darling: Estadística = {ad_statistic}")
print(f"Valores críticos = {ad_critical_values}")
print(f"Nivel de significancia = {ad_significance_level}")
```

### Explicación

#### 🧪 Test de Kolmogorov-Smirnov
- **Estadística**: Mide la diferencia máxima entre la distribución acumulativa empírica de la muestra y la distribución acumulativa teórica (exponencial).
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hipótesis nula de que la muestra sigue una distribución exponencial.

#### 🔍 Test de Anderson-Darling
- **Estadística**: Da más peso a los extremos de la distribución al medir la adecuación de la muestra a una distribución teórica (exponencial).
- **Valores críticos**: Si la estadística de Anderson-Darling es mayor que el valor crítico correspondiente al nivel de significancia, se rechaza la hipótesis nula de que la muestra sigue una distribución exponencial.

### Resultados de Ejemplo

```plaintext
Test de Kolmogorov-Smirnov: Estadística = 0.0300, P-valor = 0.3244
Test de Anderson-Darling: Estadística = 0.5122
Valores críticos = [0.921, 1.077, 1.340, 1.605, 1.956]
Nivel de significancia = [15.0, 10.0, 5.0, 2.5, 1.0]
```

### Interpretación de los Resultados

#### 🧪 Test de Kolmogorov-Smirnov
- **P-valor: 0.3244**. Este valor es mayor que 0.05, lo que indica que no hay suficiente evidencia para rechazar la hipótesis nula. Los datos parecen seguir una distribución exponencial.

#### 🔍 Test de Anderson-Darling
- **Estadística: 0.5122**. Este valor es menor que todos los valores críticos, lo que indica que no hay suficiente evidencia para rechazar la hipótesis nula. Los datos parecen seguir una distribución exponencial.

---

## **Distribución de Poisson** 🥛

Es una distribución de probabilidad discreta que describe **el número de eventos que ocurren en un intervalo de tiempo o espacio fijo**, conociendo la tasa promedio de ocurrencia de esos eventos. Es especialmente útil para modelar eventos raros o inusuales. La función de probabilidad de una distribución de Poisson se define como:

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

donde:
- \( k \) es el número de eventos (0, 1, 2, ...).
- \( \lambda \) es la tasa promedio de ocurrencia de eventos por intervalo (también conocido como el parámetro de Poisson).
- \( e \) es la base del logaritmo natural (aproximadamente igual a 2.71828).

### Ejemplo de Distribución de Poisson

#### Problema:
Supongamos que una central de llamadas recibe en promedio 5 llamadas por minuto. Queremos calcular la probabilidad de que la central reciba exactamente 7 llamadas en un minuto.

#### Solución:
Usamos la fórmula de la distribución de Poisson:

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

donde:
- \( \lambda = 5 \) (tasa promedio de llamadas por minuto)
- \( k = 7 \) (número de llamadas que queremos calcular la probabilidad)

Reemplazamos estos valores en la fórmula:

\[ P(X = 7) = \frac{5^7 e^{-5}}{7!} \]

Calculamos los valores:

\[ 5^7 = 78125 \]
\[ e^{-5} \approx 0.00674 \]
\[ 7! = 5040 \]

Entonces:

\[ P(X = 7) = \frac{78125 \times 0.00674}{5040} \approx 0.104 \]

Por lo tanto, la probabilidad de recibir exactamente 7 llamadas en un minuto es aproximadamente 0.104, o 10.4%.

![Distribución de Poisson](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Poisson.png)

---

## Tipos de Sesgo en Distribuciones 💹

El **sesgo en las distribuciones de datos** se refiere a la asimetría en la distribución de datos en relación con su media. Existen tres tipos principales de sesgo en las distribuciones de datos:

1. **👈 Sesgo a la Izquierda (Negativo):**
   - La cola de la distribución se extiende más hacia la izquierda.
   - La mayoría de los datos están concentrados en el lado derecho de la media.
   - Ejemplo: Ingresos de una población donde hay pocos ingresos muy bajos y muchos ingresos medios y altos.

2. **〰 Distribución Simétrica (Normal):**
   - La distribución no está sesgada ni a la izquierda ni a la derecha.
   - La media, la mediana y la moda son iguales.
   - Ejemplo: Alturas de una población donde la mayoría de las personas tienen una altura cercana a la media.

3. **👉 Sesgo a la Derecha (Positivo):**
   - La cola de la distribución se extiende más hacia la derecha.
   - La mayoría de los datos están concentrados en el lado izquierdo de la media.
   - Ejemplo: Ingresos de una población donde hay muchos ingresos bajos y pocos ingresos muy altos.

   ![Distribución Sesgada a la Derecha](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20media%20y%20mediana.png)

### 🔀 Media y Mediana en Distribuciones Sesgadas 🔀

La **media** y la **mediana** son medidas de tendencia central que se utilizan para describir la distribución de un conjunto de datos. La relación entre la media y la mediana puede proporcionar información sobre la asimetría de la distribución de los datos (sesgo).

### Generación de Datos y Gráficos de Forma más Avanzada

Vamos a generar datos para tres tipos de distribuciones y ubicar la media y la mediana en cada una.

#### Código Python:

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)

# Sesgo a la izquierda (Negativo)
left_skewed_data = np.random.beta(a=2, b=5, size=1000) * 10
left_mean = np.mean(left_skewed_data)
left_median = np.median(left_skewed_data)

# Distribución Normal (Simétrica)
normal_data = np.random.normal(loc=5, scale=1, size=1000)
normal_mean = np.mean(normal_data)
normal_median = np.median(normal_data)

# Sesgo a la derecha (Positivo)
right_skewed_data = np.random.beta(a=5, b=2, size=1000) * 10
right_mean = np.mean(right_skewed_data)
right_median = np.median(right_skewed_data)

# Crear histogramas para cada distribución
fig, axes = plt.subplots(3, 1, figsize=(8, 12))

# Distribución Sesgada a la Izquierda
axes[0].hist(left_skewed_data, bins=30, color='blue', alpha=0.7, edgecolor='black')
axes[0].axvline(left_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {left_mean:.2f}')
axes[0].axvline(left_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {left_median:.2f}')
axes[0].set_title('Distribución Sesgada a la Izquierda (Sesgo Negativo)')
axes[0].set_xlabel('Valor')
axes[0].set_ylabel('Frecuencia')
axes[0].legend()

# Distribución Normal
axes[1].hist(normal_data, bins=30, color='green', alpha=0.7, edgecolor='black')
axes[1].axvline(normal_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {normal_mean:.2f}')
axes[1].axvline(normal_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {normal_median:.2f}')
axes[1].set_title('Distribución Normal (Simétrica)')
axes[1].set_xlabel('Valor')
axes[1].set_ylabel('Frecuencia')
axes[1].legend()

# Distribución Sesgada a la Derecha
axes[2].hist(right_skewed_data, bins=30, color='red', alpha=0.7, edgecolor='black')
axes[2].axvline(right_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {right_mean:.2f}')
axes[2].axvline(right_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {right_median:.2f}')
axes[2].set_title('Distribución Sesgada a la Derecha (Sesgo Positivo)')
axes[2].set_xlabel('Valor')
axes[2].set_ylabel('Frecuencia')
axes[2].legend()

# Ajustar el diseño
plt.tight_layout()

plt.show()
```

### Explicación

#### 📉 Distribución Sesgada a la Izquierda (Sesgo Negativo)
- La cola de la distribución se extiende hacia la izquierda.
- La **media** es menor que la **mediana**.
- Esto significa que hay más valores altos y pocos valores muy bajos.

#### 🔄 Distribución Normal (Simétrica)
- La distribución no está sesgada ni a la izquierda ni a la derecha.
- La **media** y la **mediana** son iguales.
- Esto significa que los datos están distribuidos uniformemente alrededor del centro.

#### 📈 Distribución Sesgada a la Derecha (Sesgo Positivo)
- La cola de la distribución se extiende hacia la derecha.
- La **media** es mayor que la **mediana**.
- Esto significa que hay más valores bajos y pocos valores muy altos.

### 📈 Imagen de Distribuciones con Media y Mediana

![Distribuciones Sesgadas con Media y Mediana](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20media%20y%20mediana.png)

Este gráfico muestra cómo se ubican la media y la mediana en distribuciones sesgadas a la izquierda, normales y sesgadas a la derecha, y ayuda a entender el significado de la relación entre la media y la mediana en cada caso.
---
## 🏁 **Conclusión** 🏁

La estadística inferencial es una herramienta poderosa que permite tomar decisiones informadas y hacer predicciones basadas en datos muestrales. Es fundamental comprender los conceptos de hipótesis, intervalos de confianza y errores para interpretar correctamente los resultados.

Con estos conocimientos, ahora tienes las herramientas necesarias para comprender y aplicar conceptos de estadística inferencial, permitiendo hacer inferencias sobre poblaciones a partir de muestras, realizar pruebas de hipótesis y calcular intervalos de confianza. ¡Continúa practicando y experimentando con diferentes tipos de análisis para mejorar tus habilidades en estadística inferencial!



