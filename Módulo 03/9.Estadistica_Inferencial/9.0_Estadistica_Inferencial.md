# üßô‚Äç‚ôÄÔ∏è **Estad√≠stica Inferencial** üßô‚Äç‚ôÄÔ∏è 

---

## üîç **Definici√≥n** üîç

La estad√≠stica inferencial permite hacer generalizaciones sobre una poblaci√≥n bas√°ndose en los datos obtenidos de una muestra. A diferencia de la estad√≠stica descriptiva, que se enfoca en describir los datos, la inferencial se centra en hacer predicciones y pruebas de hip√≥tesis.

---

## üìà **¬øQu√© diferencia hay entre estad√≠stica descriptiva y estad√≠stica inferencial?** üìà

1. **Estad√≠stica Descriptiva:** üìã  
   Se utiliza para describir y resumir los datos de una muestra mediante gr√°ficos, tablas y medidas de resumen como la media, mediana y desviaci√≥n est√°ndar.

2. **Estad√≠stica Inferencial:** üìä  
   Se utiliza para hacer inferencias sobre una poblaci√≥n a partir de una muestra, utilizando m√©todos como intervalos de confianza y pruebas de hip√≥tesis.

---

## üìö **Conceptos de Poblaci√≥n y Muestra** üìö

1. **Poblaci√≥n:** üåç  
   Es el conjunto completo de todos los elementos que estamos interesados en estudiar.

2. **Muestra:** üìä  
   Es un subconjunto de la poblaci√≥n que se selecciona para el estudio. Debe ser representativa para que las conclusiones sean v√°lidas.

3. **Diferencia entre Poblaci√≥n y Muestra:** üîç  
   La poblaci√≥n incluye todos los elementos posibles de estudio, mientras que la muestra es solo una parte seleccionada de la poblaci√≥n.

---

## üìâ **Distribuci√≥n de la Muestra** üìâ

La distribuci√≥n de la muestra describe c√≥mo se distribuyen los valores de la muestra y se utiliza para hacer inferencias sobre la poblaci√≥n.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
muestra = np.random.normal(loc=0, scale=1, size=1000)

# Visualizar la distribuci√≥n de la muestra
plt.figure(figsize=(10, 6))
sns.histplot(muestra, kde=True, color='blue')
plt.title('Distribuci√≥n de la Muestra')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_de_la_Muestra.png")
plt.show()
```

![Distribuci√≥n de la Muestra](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20de%20la%20Muestra.png)

---

## ‚öñÔ∏è **Hip√≥tesis Nula vs Hip√≥tesis Alternativa** ‚öñÔ∏è

1. **Hip√≥tesis Nula (H0):** ‚ùå  
   Es una afirmaci√≥n general o defecto que no hay efecto o diferencia. **Asumimos que la distribuci√≥n es normal**.
   - **Mayor de 0.05 Acepto la Hip√≥tesis Nula**.
   - **Menor de 0.05 Rechazo la Hip√≥tesis Nula**. 

3. **Hip√≥tesis Alternativa (H1):** ‚úîÔ∏è  
   Es lo opuesto a la hip√≥tesis nula, indicando que hay un efecto o una diferencia significativa.**Asumimos que la distribuci√≥n NO es normal**.

![Hip√≥tesis Nula vs Hip√≥tesis Alternativa](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Hip%C3%B3tesis%20Nula%20vs%20Hip%C3%B3tesis%20ALternativa.png)

### üìù **Pasos en la Prueba de Hip√≥tesis** üìù

1. Plantear las hip√≥tesis nula y alternativa.
2. Seleccionar un nivel de significancia.
3. Recopilar y analizar los datos de la muestra.
4. Tomar una decisi√≥n basada en los resultados.

---

## üìè **Intervalos de Confianza** üìè

Un intervalo de confianza proporciona un rango de valores, derivado de los datos de la muestra, que probablemente contiene el valor verdadero del par√°metro de la poblaci√≥n. El rango sobre el que suponemos que van a caer la mayor parte de nuestros datos. 

```python
import numpy as np
import scipy.stats as stats

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=1000)

# Calcular el intervalo de confianza del 95%
confianza = 0.95
media = np.mean(data)
error_estandar = stats.sem(data)
intervalo = error_estandar * stats.t.ppf((1 + confianza) / 2., len(data)-1)

intervalo_confianza = (media - intervalo, media + intervalo)
print(f"Intervalo de confianza del 95%: {intervalo_confianza}")
```

Ejemplo, por si queremos crear los datos sint√©ticamente en un DataFrame y encontrar el intervalo de confianza:

```python
import pandas as pd
import numpy as np
from scipy import stats

# Crear datos sint√©ticos
np.random.seed(42)  # Fijar semilla para reproducibilidad
data = {
    'continente': ['Asia', 'Europa', '√Åfrica', 'Am√©rica', 'Ocean√≠a'] * 20,  # Lista de continentes repetidos 20 veces cada uno
    'esperanza_de_vida': np.concatenate([
        np.random.normal(70, 5, 20),  # Generar 20 valores para Asia con promedio 70 y desviaci√≥n 5
        np.random.normal(80, 4, 20),  # Generar 20 valores para Europa con promedio 80 y desviaci√≥n 4
        np.random.normal(60, 6, 20),  # Generar 20 valores para √Åfrica con promedio 60 y desviaci√≥n 6
        np.random.normal(75, 5, 20),  # Generar 20 valores para Am√©rica con promedio 75 y desviaci√≥n 5
        np.random.normal(78, 3, 20)   # Generar 20 valores para Ocean√≠a con promedio 78 y desviaci√≥n 3
    ])
}

df = pd.DataFrame(data)  # Crear un DataFrame con los datos

# Asegurarse de que no hay valores nulos
df = df.dropna(subset=['continente', 'esperanza_de_vida'])  # Eliminar filas con valores nulos en las columnas especificadas

# Calcular la esperanza de vida promedio y la desviaci√≥n est√°ndar por continente
estadisticas = df.groupby('continente')['esperanza_de_vida'].agg(['mean', 'std', 'count']).reset_index()  # Calcular media, desviaci√≥n est√°ndar y cantidad por continente
estadisticas = estadisticas.rename(columns={'mean': 'media', 'std': 'desviacion_std', 'count': 'n'})  # Renombrar columnas para claridad

# Calcular el intervalo de confianza al 95%
confianza = 0.95  # Establecer el nivel de confianza
media = np.mean(df['esperanza_de_vida'])  # Calcular la media de la esperanza de vida
error_estandar = stats.sem(df['esperanza_de_vida'])  # Calcular el error est√°ndar de la media

# Calcular el intervalo de confianza
intervalo = error_estandar * stats.t.ppf((1 + confianza) / 2., len(df) - 1)  # Calcular el margen de error
intervalo_confianza = (media - intervalo, media + intervalo)  # Calcular el intervalo de confianza
print(f"Intervalo de confianza del 95%: {intervalo_confianza}")  # Imprimir el intervalo de confianza

```

![Intervalos de Confianza](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Intervalos%20de%20Confianza.png)

[Intervalo de Confianza Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Jupyters/modulo-3-leccion-09-04-intervalo-confianza.ipynb)  

---

## ‚ö†Ô∏è **Error Tipo I y Tipo II** ‚ö†Ô∏è

1. **Error Tipo I:** ‚ùå  
   Rechazar la hip√≥tesis nula cuando es verdadera.

2. **Error Tipo II:** ‚ùå  
   No rechazar la hip√≥tesis nula cuando es falsa.

![Errores Tipo I y Tipo II](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Error%20Tipo%20I%20y%20Error%20Tipo%20II.png)

---

## üìê **Distribuci√≥n Muestral de la Media** üìê

La distribuci√≥n de la media muestral se utiliza para entender c√≥mo var√≠a la media de la muestra y se aproxima a la distribuci√≥n normal seg√∫n el Teorema Central del L√≠mite.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
muestras = [np.random.normal(loc=0, scale=1, size=30) for _ in range(1000)]
medias_muestrales = [np.mean(muestra) for muestra in muestras]

# Visualizar la distribuci√≥n de la media muestral
plt.figure(figsize=(10, 6))
sns.histplot(medias_muestrales, kde=True, color='green')
plt.title('Distribuci√≥n Muestral de la Media')
plt.xlabel('Media Muestral')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Muestral_de_la_Media.png")
plt.show()
```

![Distribuci√≥n Muestral de la Media](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20Muestral%20de%20la%20Media.png)

---

## üîç **Pruebas de Hip√≥tesis** üîç

Las pruebas de hip√≥tesis son procedimientos que permiten decidir si los datos de la muestra proporcionan suficiente evidencia para rechazar la hip√≥tesis nula.

[Prueba de Hip√≥tesis Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Jupyters/modulo-3-leccion-09-05-prueba-hipotesis.ipynb)

---

### üìë **Tipos de Pruebas** üìë

1. **Prueba t de Student:** üßÆ  
   Utilizada para comparar las medias de dos grupos independientes.

```python
import numpy as np
from scipy.stats import ttest_ind

# Generar datos de ejemplo
np.random.seed(0)
grupo1 = np.random.normal(loc=0, scale=1, size=100)
grupo2 = np.random.normal(loc=1, scale=1, size=100)

# Realizar la prueba t de Student
t_stat, p_value = ttest_ind(grupo1, grupo2)
print(f"t-statistic: {t_stat}, p-value: {p_value}")
```

2. **Prueba Z:** üßÆ  
   Utilizada cuando el tama√±o de la muestra es grande y la varianza es conocida.

```python
import numpy as np
from statsmodels.stats.weightstats import ztest

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=1000)

# Realizar la prueba Z
z_stat, p_value = ztest(data)
print(f"z-statistic: {z_stat}, p-value: {p_value}")
```

3. **Pruebas no param√©tricas:** üìè  
   Utilizadas cuando no se cumplen las suposiciones de las pruebas param√©tricas.

```python
import numpy as np
from scipy.stats import mannwhitneyu

# Generar datos de ejemplo
np.random.seed(0)
grupo1 = np.random.normal(loc=0, scale=1, size=100)
grupo2 = np.random.normal(loc=1, scale=1, size=100)

# Realizar la prueba de Mann-Whitney
u_stat, p_value = mannwhitneyu(grupo1, grupo2)
print(f"U-statistic: {u_stat}, p-value: {p_value}")
```

---

## üìè **Distribuciones: Normal, Uniforme y Exponencial** üìè

## **Distribuci√≥n Normal o Gaussiana** üìà

La distribuci√≥n normal, tambi√©n conocida como distribuci√≥n gaussiana, es una de las distribuciones de probabilidad m√°s importantes en estad√≠stica. Se caracteriza por tener una forma de campana y est√° completamente definida por su media (Œº) y su desviaci√≥n est√°ndar (œÉ).

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_normales = np.random.normal(loc=0, scale=1, size=1000)

# Visualizar la distribuci√≥n normal
plt.figure(figsize=(10, 6))
sns.histplot(datos_normales, kde=True, color='purple')
plt.title('Distribuci√≥n Normal')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Normal.png")
plt.show()
```
Claro, aqu√≠ tienes un ejemplo de c√≥mo se puede aplicar la distribuci√≥n normal:

### Ejemplo de Distribuci√≥n Normal

#### Problema:
Supongamos que las alturas de los hombres adultos en una poblaci√≥n siguen una distribuci√≥n normal con una media (\(\mu\)) de 175 cm y una desviaci√≥n est√°ndar (\(\sigma\)) de 10 cm. Queremos calcular la probabilidad de que un hombre elegido al azar tenga una altura entre 165 cm y 185 cm.

#### Soluci√≥n:
En una distribuci√≥n normal, calculamos la probabilidad de un intervalo usando la funci√≥n de distribuci√≥n acumulativa (CDF). Sin embargo, para simplificar el c√°lculo, podemos usar la tabla Z o una calculadora de distribuci√≥n normal est√°ndar.

Primero, convertimos las alturas a valores Z:

\[ Z = \frac{X - \mu}{\sigma} \]

Para \( X = 165 \) cm:

\[ Z_{165} = \frac{165 - 175}{10} = \frac{-10}{10} = -1 \]

Para \( X = 185 \) cm:

\[ Z_{185} = \frac{185 - 175}{10} = \frac{10}{10} = 1 \]

Usando una tabla Z o una calculadora de distribuci√≥n normal, encontramos las probabilidades correspondientes a estos valores Z:

- La probabilidad de \( Z \leq -1 \) es aproximadamente 0.1587.
- La probabilidad de \( Z \leq 1 \) es aproximadamente 0.8413.

Para encontrar la probabilidad de que \( X \) est√© entre 165 cm y 185 cm, restamos estas probabilidades:

\[ P(165 \leq X \leq 185) = P(Z \leq 1) - P(Z \leq -1) \]
\[ P(165 \leq X \leq 185) = 0.8413 - 0.1587 = 0.6826 \]

Por lo tanto, la probabilidad de que un hombre elegido al azar tenga una altura entre 165 cm y 185 cm es aproximadamente 0.6826, o 68.26%.

[Distribuci√≥n Normal Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### üîù Test de Kolmogorov-Smirnov y Test de Shapiro-Wilk

Los tests de Kolmogorov-Smirnov y Shapiro-Wilk son pruebas estad√≠sticas utilizadas para determinar si una muestra sigue una distribuci√≥n normal. A continuaci√≥n se presentan ejemplos de c√≥mo utilizar estos tests con Python.

#### C√≥digo Python para Test de Kolmogorov-Smirnov y Test de Shapiro-Wilk:

```python
import numpy as np
from scipy.stats import kstest, shapiro

# Generar datos normales
np.random.seed(42)
datos_normal = np.random.normal(loc=0, scale=1, size=1000)

# Test de Kolmogorov-Smirnov
p_value_k = kstest(datos_normal, "norm").pvalue
print(f"P-valor del test de Kolmogorov-Smirnov: {p_value_k}")

# Test de Shapiro-Wilk
p_value_s = shapiro(datos_normal).pvalue
print(f"P-valor del test de Shapiro-Wilk: {p_value_s}")

```

### Explicaci√≥n

#### üìâ Test de Kolmogorov-Smirnov
- Este test compara la muestra con una distribuci√≥n de referencia (en este caso, la normal).
- La **estad√≠stica** mide la distancia m√°xima entre la funci√≥n de distribuci√≥n acumulativa de la muestra y la de la distribuci√≥n de referencia.
- Un **p-valor** alto indica que no se puede rechazar la hip√≥tesis nula de que la muestra sigue la distribuci√≥n de referencia.
- **Se utiliza para muestras m√°s grandes (m√°s de 500).**

#### üìà Test de Shapiro-Wilk
- Este test eval√∫a si una muestra sigue una distribuci√≥n normal.
- La **estad√≠stica** se basa en la correlaci√≥n entre los datos y los valores esperados de una distribuci√≥n normal.
- Un **p-valor** alto indica que no se puede rechazar la hip√≥tesis nula de que la muestra sigue una distribuci√≥n normal.
- **Se utiliza para muestras m√°s peque√±as (menos de 500).**
  
#### Resultados 

```plaintext
P-valor del test de Kolmogorov-Smirnov: 0.6180
P-valor del test de Shapiro-Wilk: 0.5911
```
---

## **Distribuci√≥n Uniforme** üìè

Una distribuci√≥n uniforme es un tipo de distribuci√≥n de probabilidad en la que todos los valores posibles tienen la misma probabilidad de ocurrir. Tiene una gr√°fica casi plana. 

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_uniformes = np.random.uniform(low=0, high=1, size=1000)

# Visualizar la distribuci√≥n uniforme
plt.figure(figsize=(10, 6))
sns.histplot(datos_uniformes, kde=True, color='orange')
plt.title('Distribuci√≥n Uniforme')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Uniforme.png")
plt.show()
```
### Ejemplo de Distribuci√≥n Uniforme

#### Problema:
Supongamos que un reloj digital muestra minutos del 00 al 59. Queremos calcular la probabilidad de que cuando miramos el reloj, los minutos mostrados sean entre 15 y 30.

#### Soluci√≥n:
En una distribuci√≥n uniforme continua, cada valor dentro del rango es igualmente probable. La funci√≥n de densidad de probabilidad para una distribuci√≥n uniforme continua est√° definida como:

\[ f(x) = \frac{1}{b-a} \]

donde:
- \( a \) y \( b \) son los l√≠mites inferior y superior del intervalo.

En este caso, \( a = 0 \) y \( b = 59 \).

La probabilidad de que el valor est√© entre 15 y 30 se puede calcular como el √°rea bajo la curva de densidad de probabilidad en ese intervalo. Esto es simplemente la longitud del intervalo dividido por la longitud total del rango.

\[ P(15 \leq X \leq 30) = \frac{30 - 15}{59 - 0} = \frac{15}{59} \]

Calculamos la probabilidad:

\[ P(15 \leq X \leq 30) = \frac{15}{59} \approx 0.254 \]

Por lo tanto, la probabilidad de que los minutos mostrados en el reloj est√©n entre 15 y 30 es aproximadamente 0.254, o 25.4%.

[Distribuci√≥n Uniforme Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### ‚ú¥ Test para Determinar si los Datos son Uniformes

Para determinar si una muestra de datos sigue una distribuci√≥n uniforme, se pueden utilizar varios tests estad√≠sticos. Algunos de los m√°s comunes son:

### 1. üß™ Test de Kolmogorov-Smirnov
El test de Kolmogorov-Smirnov (KS) es uno de los m√©todos m√°s populares para comparar una muestra con una distribuci√≥n de referencia (en este caso, la distribuci√≥n uniforme). Este test eval√∫a la m√°xima diferencia entre la funci√≥n de distribuci√≥n acumulativa emp√≠rica de la muestra y la funci√≥n de distribuci√≥n acumulativa te√≥rica.

### 2. üîç Chi-cuadrado de Pearson
El test de Chi-cuadrado es √∫til para comparar la frecuencia observada de los datos con las frecuencias esperadas bajo una distribuci√≥n uniforme. Este test es especialmente adecuado cuando los datos son categ√≥ricos o se han agrupado en intervalos.

### 3. üìâ Test de Anderson-Darling
El test de Anderson-Darling es una modificaci√≥n del test de Kolmogorov-Smirnov que da m√°s peso a los extremos de la distribuci√≥n. Es un test de bondad de ajuste que se puede utilizar para comparar una muestra con una distribuci√≥n uniforme.

### Ejemplo de C√≥digo en Python para el Test de Kolmogorov-Smirnov y Chi-cuadrado

#### C√≥digo Python:

```python
import numpy as np
from scipy.stats import kstest, chisquare

# Generar datos
np.random.seed(42)
datos_uniformes = np.random.uniform(low=0, high=1, size=1000)

# Test de Kolmogorov-Smirnov
ks_statistic, ks_p_value = kstest(datos_uniformes, 'uniform', args=(0, 1))
print(f"Test de Kolmogorov-Smirnov: Estad√≠stica = {ks_statistic}, P-valor = {ks_p_value}")

# Agrupar datos para el test de Chi-cuadrado
observed, bins = np.histogram(datos_uniformes, bins=10)
expected = np.ones(10) * len(datos_uniformes) / 10

# Test de Chi-cuadrado
chi_statistic, chi_p_value = chisquare(observed, expected)
print(f"Test de Chi-cuadrado: Estad√≠stica = {chi_statistic}, P-valor = {chi_p_value}")
```

### Explicaci√≥n

#### üß™ Test de Kolmogorov-Smirnov
- **Estad√≠stica**: Mide la diferencia m√°xima entre la distribuci√≥n acumulativa emp√≠rica de la muestra y la distribuci√≥n acumulativa te√≥rica (uniforme).
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula de que la muestra sigue una distribuci√≥n uniforme.

#### üîç Test de Chi-cuadrado Pearson
- **Estad√≠stica**: Mide la diferencia entre las frecuencias observadas y esperadas en cada intervalo.
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula de que las frecuencias observadas se ajustan a las frecuencias esperadas bajo una distribuci√≥n uniforme.

### Resultados de Ejemplo

```plaintext
Test de Kolmogorov-Smirnov: Estad√≠stica = 0.0172, P-valor = 0.8142
Test de Chi-cuadrado: Estad√≠stica = 10.0, P-valor = 0.4417
```

Estos resultados sugieren que, para ambos tests, los datos parecen seguir una distribuci√≥n uniforme, ya que los p-valores **son mayores que 0.05**.

---

## **Distribuci√≥n Exponencial** üìà

La distribuci√≥n exponencial es una distribuci√≥n de probabilidad que describe **el tiempo entre eventos sucesivos e independientes en un proceso**.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Visualizar la distribuci√≥n exponencial
plt.figure(figsize=(10, 6))
sns.histplot(datos_exponenciales, kde=True, color='green')
plt.title('Distribuci√≥n Exponencial')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Exponencial.png")
plt.show()
```
Claro, aqu√≠ tienes un ejemplo de c√≥mo se puede aplicar la distribuci√≥n exponencial:

### Ejemplo de Distribuci√≥n Exponencial

#### Problema:
Supongamos que el tiempo que una persona espera en una cola de banco sigue una distribuci√≥n exponencial con una tasa promedio (\(\lambda\)) de 2 clientes por minuto. Queremos calcular la probabilidad de que una persona espere menos de 1 minuto en la cola.

#### Soluci√≥n:
En una distribuci√≥n exponencial, la funci√≥n de densidad de probabilidad est√° definida como:

\[ f(x; \lambda) = \lambda e^{-\lambda x} \]

donde:
- \( x \) es el tiempo de espera.
- \( \lambda \) es la tasa promedio de ocurrencia de eventos.

La funci√≥n de distribuci√≥n acumulativa (CDF) para una distribuci√≥n exponencial, que nos da la probabilidad de que el tiempo de espera sea menor o igual a un cierto valor \( x \), est√° definida como:

\[ F(x; \lambda) = 1 - e^{-\lambda x} \]

Para calcular la probabilidad de que una persona espere menos de 1 minuto:

\[ P(X < 1) = 1 - e^{-\lambda \cdot 1} = 1 - e^{-2 \cdot 1} \]

Calculamos el valor:

\[ P(X < 1) = 1 - e^{-2} \approx 1 - 0.1353 = 0.8647 \]

Por lo tanto, la probabilidad de que una persona espere menos de 1 minuto en la cola es aproximadamente 0.8647, o 86.47%.

[Distribuci√≥n Exponencial Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### üìä Test para Determinar si los Datos siguen una Distribuci√≥n Exponencial

Para determinar si una muestra de datos sigue una distribuci√≥n exponencial, se pueden utilizar varios tests estad√≠sticos. Algunos de los m√°s comunes son:

### 1. üß™ Test de Kolmogorov-Smirnov
El test de Kolmogorov-Smirnov (KS) se puede usar para comparar una muestra con una distribuci√≥n de referencia (en este caso, la distribuci√≥n exponencial). Este test eval√∫a la m√°xima diferencia entre la funci√≥n de distribuci√≥n acumulativa emp√≠rica de la muestra y la funci√≥n de distribuci√≥n acumulativa te√≥rica.

### 2. üîç Test de Anderson-Darling
El test de Anderson-Darling es una modificaci√≥n del test de Kolmogorov-Smirnov que da m√°s peso a los extremos de la distribuci√≥n. Es adecuado para probar si una muestra sigue una distribuci√≥n exponencial.

### 3. üìâ Test de Chi-cuadrado
El test de Chi-cuadrado se puede utilizar para comparar la frecuencia observada de los datos con las frecuencias esperadas bajo una distribuci√≥n exponencial, especialmente cuando los datos se agrupan en intervalos.

### Ejemplo de C√≥digo en Python para el Test de Kolmogorov-Smirnov y Anderson-Darling

#### C√≥digo Python:

```python
import numpy as np
from scipy.stats import kstest, anderson

# Generar datos exponenciales
np.random.seed(42)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Test de Kolmogorov-Smirnov
ks_statistic, ks_p_value = kstest(datos_exponenciales, 'expon', args=(0, 1))
print(f"Test de Kolmogorov-Smirnov: Estad√≠stica = {ks_statistic}, P-valor = {ks_p_value}")

# Test de Anderson-Darling
ad_statistic, ad_critical_values, ad_significance_level = anderson(datos_exponenciales, 'expon')
print(f"Test de Anderson-Darling: Estad√≠stica = {ad_statistic}")
print(f"Valores cr√≠ticos = {ad_critical_values}")
print(f"Nivel de significancia = {ad_significance_level}")
```

### Explicaci√≥n

#### üß™ Test de Kolmogorov-Smirnov
- **Estad√≠stica**: Mide la diferencia m√°xima entre la distribuci√≥n acumulativa emp√≠rica de la muestra y la distribuci√≥n acumulativa te√≥rica (exponencial).
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula de que la muestra sigue una distribuci√≥n exponencial.

#### üîç Test de Anderson-Darling
- **Estad√≠stica**: Da m√°s peso a los extremos de la distribuci√≥n al medir la adecuaci√≥n de la muestra a una distribuci√≥n te√≥rica (exponencial).
- **Valores cr√≠ticos**: Si la estad√≠stica de Anderson-Darling es mayor que el valor cr√≠tico correspondiente al nivel de significancia, se rechaza la hip√≥tesis nula de que la muestra sigue una distribuci√≥n exponencial.

### Resultados de Ejemplo

```plaintext
Test de Kolmogorov-Smirnov: Estad√≠stica = 0.0288, P-valor = 0.3134
Test de Anderson-Darling: Estad√≠stica = 0.639
Valores cr√≠ticos = [1.31 1.48 1.73 2.02 2.51]
Nivel de significancia = 15.0
```

### Interpretaci√≥n de los Resultados

#### üß™ Test de Kolmogorov-Smirnov
- **P-valor: 0.3134**. Este valor es mayor que 0.05, lo que indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula. Los datos parecen seguir una distribuci√≥n exponencial.

#### üîç Test de Anderson-Darling
- **Estad√≠stica: 0.639**. Este valor es menor que todos los valores cr√≠ticos, lo que indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula. Los datos parecen seguir una distribuci√≥n exponencial.

### üìâüìà Im√°genes de Distribuciones

Voy a generar im√°genes para ilustrar los resultados de los tests aplicados a una muestra de datos exponenciales.

### üìä Test para Determinar si los Datos siguen una Distribuci√≥n Exponencial

#### Ejemplo de C√≥digo en Python para el Test de Kolmogorov-Smirnov y Anderson-Darling

```python
import numpy as np
from scipy.stats import kstest, anderson

# Generar datos exponenciales
np.random.seed(42)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Test de Kolmogorov-Smirnov
ks_statistic, ks_p_value = kstest(datos_exponenciales, 'expon', args=(0, 1))
print(f"Test de Kolmogorov-Smirnov: Estad√≠stica = {ks_statistic}, P-valor = {ks_p_value}")

# Test de Anderson-Darling
ad_statistic, ad_critical_values, ad_significance_level = anderson(datos_exponenciales, 'expon')
print(f"Test de Anderson-Darling: Estad√≠stica = {ad_statistic}")
print(f"Valores cr√≠ticos = {ad_critical_values}")
print(f"Nivel de significancia = {ad_significance_level}")
```

### Explicaci√≥n

#### üß™ Test de Kolmogorov-Smirnov
- **Estad√≠stica**: Mide la diferencia m√°xima entre la distribuci√≥n acumulativa emp√≠rica de la muestra y la distribuci√≥n acumulativa te√≥rica (exponencial).
- **P-valor**: Un valor alto (mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula de que la muestra sigue una distribuci√≥n exponencial.

#### üîç Test de Anderson-Darling
- **Estad√≠stica**: Da m√°s peso a los extremos de la distribuci√≥n al medir la adecuaci√≥n de la muestra a una distribuci√≥n te√≥rica (exponencial).
- **Valores cr√≠ticos**: Si la estad√≠stica de Anderson-Darling es mayor que el valor cr√≠tico correspondiente al nivel de significancia, se rechaza la hip√≥tesis nula de que la muestra sigue una distribuci√≥n exponencial.

### Resultados de Ejemplo

```plaintext
Test de Kolmogorov-Smirnov: Estad√≠stica = 0.0300, P-valor = 0.3244
Test de Anderson-Darling: Estad√≠stica = 0.5122
Valores cr√≠ticos = [0.921, 1.077, 1.340, 1.605, 1.956]
Nivel de significancia = [15.0, 10.0, 5.0, 2.5, 1.0]
```

### Interpretaci√≥n de los Resultados

#### üß™ Test de Kolmogorov-Smirnov
- **P-valor: 0.3244**. Este valor es mayor que 0.05, lo que indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula. Los datos parecen seguir una distribuci√≥n exponencial.

#### üîç Test de Anderson-Darling
- **Estad√≠stica: 0.5122**. Este valor es menor que todos los valores cr√≠ticos, lo que indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula. Los datos parecen seguir una distribuci√≥n exponencial.

---

## **Distribuci√≥n de Poisson** ü•õ

Es una distribuci√≥n de probabilidad discreta que describe **el n√∫mero de eventos que ocurren en un intervalo de tiempo o espacio fijo**, conociendo la tasa promedio de ocurrencia de esos eventos. Es especialmente √∫til para modelar eventos raros o inusuales. La funci√≥n de probabilidad de una distribuci√≥n de Poisson se define como:

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

donde:
- \( k \) es el n√∫mero de eventos (0, 1, 2, ...).
- \( \lambda \) es la tasa promedio de ocurrencia de eventos por intervalo (tambi√©n conocido como el par√°metro de Poisson).
- \( e \) es la base del logaritmo natural (aproximadamente igual a 2.71828).

### Ejemplo de Distribuci√≥n de Poisson

#### Problema:
Supongamos que una central de llamadas recibe en promedio 5 llamadas por minuto. Queremos calcular la probabilidad de que la central reciba exactamente 7 llamadas en un minuto.

#### Soluci√≥n:
Usamos la f√≥rmula de la distribuci√≥n de Poisson:

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

donde:
- \( \lambda = 5 \) (tasa promedio de llamadas por minuto)
- \( k = 7 \) (n√∫mero de llamadas que queremos calcular la probabilidad)

Reemplazamos estos valores en la f√≥rmula:

\[ P(X = 7) = \frac{5^7 e^{-5}}{7!} \]

Calculamos los valores:

\[ 5^7 = 78125 \]
\[ e^{-5} \approx 0.00674 \]
\[ 7! = 5040 \]

Entonces:

\[ P(X = 7) = \frac{78125 \times 0.00674}{5040} \approx 0.104 \]

Por lo tanto, la probabilidad de recibir exactamente 7 llamadas en un minuto es aproximadamente 0.104, o 10.4%.

![Distribuci√≥n de Poisson](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Poisson.png)

---

## Tipos de Sesgo en Distribuciones üíπ

El **sesgo en las distribuciones de datos** se refiere a la asimetr√≠a en la distribuci√≥n de datos en relaci√≥n con su media. Existen tres tipos principales de sesgo en las distribuciones de datos:

1. **üëà Sesgo a la Izquierda (Negativo):**
   - La cola de la distribuci√≥n se extiende m√°s hacia la izquierda.
   - La mayor√≠a de los datos est√°n concentrados en el lado derecho de la media.
   - Ejemplo: Ingresos de una poblaci√≥n donde hay pocos ingresos muy bajos y muchos ingresos medios y altos.

2. **„Ä∞ Distribuci√≥n Sim√©trica (Normal):**
   - La distribuci√≥n no est√° sesgada ni a la izquierda ni a la derecha.
   - La media, la mediana y la moda son iguales.
   - Ejemplo: Alturas de una poblaci√≥n donde la mayor√≠a de las personas tienen una altura cercana a la media.

3. **üëâ Sesgo a la Derecha (Positivo):**
   - La cola de la distribuci√≥n se extiende m√°s hacia la derecha.
   - La mayor√≠a de los datos est√°n concentrados en el lado izquierdo de la media.
   - Ejemplo: Ingresos de una poblaci√≥n donde hay muchos ingresos bajos y pocos ingresos muy altos.

   ![Distribuci√≥n Sesgada a la Derecha](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20media%20y%20mediana.png)

### üîÄ Media y Mediana en Distribuciones Sesgadas üîÄ

La **media** y la **mediana** son medidas de tendencia central que se utilizan para describir la distribuci√≥n de un conjunto de datos. La relaci√≥n entre la media y la mediana puede proporcionar informaci√≥n sobre la asimetr√≠a de la distribuci√≥n de los datos (sesgo).

### Generaci√≥n de Datos y Gr√°ficos de Forma m√°s Avanzada

Vamos a generar datos para tres tipos de distribuciones y ubicar la media y la mediana en cada una.

#### C√≥digo Python:

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)

# Sesgo a la izquierda (Negativo)
left_skewed_data = np.random.beta(a=2, b=5, size=1000) * 10
left_mean = np.mean(left_skewed_data)
left_median = np.median(left_skewed_data)

# Distribuci√≥n Normal (Sim√©trica)
normal_data = np.random.normal(loc=5, scale=1, size=1000)
normal_mean = np.mean(normal_data)
normal_median = np.median(normal_data)

# Sesgo a la derecha (Positivo)
right_skewed_data = np.random.beta(a=5, b=2, size=1000) * 10
right_mean = np.mean(right_skewed_data)
right_median = np.median(right_skewed_data)

# Crear histogramas para cada distribuci√≥n
fig, axes = plt.subplots(3, 1, figsize=(8, 12))

# Distribuci√≥n Sesgada a la Izquierda
axes[0].hist(left_skewed_data, bins=30, color='blue', alpha=0.7, edgecolor='black')
axes[0].axvline(left_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {left_mean:.2f}')
axes[0].axvline(left_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {left_median:.2f}')
axes[0].set_title('Distribuci√≥n Sesgada a la Izquierda (Sesgo Negativo)')
axes[0].set_xlabel('Valor')
axes[0].set_ylabel('Frecuencia')
axes[0].legend()

# Distribuci√≥n Normal
axes[1].hist(normal_data, bins=30, color='green', alpha=0.7, edgecolor='black')
axes[1].axvline(normal_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {normal_mean:.2f}')
axes[1].axvline(normal_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {normal_median:.2f}')
axes[1].set_title('Distribuci√≥n Normal (Sim√©trica)')
axes[1].set_xlabel('Valor')
axes[1].set_ylabel('Frecuencia')
axes[1].legend()

# Distribuci√≥n Sesgada a la Derecha
axes[2].hist(right_skewed_data, bins=30, color='red', alpha=0.7, edgecolor='black')
axes[2].axvline(right_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {right_mean:.2f}')
axes[2].axvline(right_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {right_median:.2f}')
axes[2].set_title('Distribuci√≥n Sesgada a la Derecha (Sesgo Positivo)')
axes[2].set_xlabel('Valor')
axes[2].set_ylabel('Frecuencia')
axes[2].legend()

# Ajustar el dise√±o
plt.tight_layout()

plt.show()
```

### Explicaci√≥n

#### üìâ Distribuci√≥n Sesgada a la Izquierda (Sesgo Negativo)
- La cola de la distribuci√≥n se extiende hacia la izquierda.
- La **media** es menor que la **mediana**.
- Esto significa que hay m√°s valores altos y pocos valores muy bajos.

#### üîÑ Distribuci√≥n Normal (Sim√©trica)
- La distribuci√≥n no est√° sesgada ni a la izquierda ni a la derecha.
- La **media** y la **mediana** son iguales.
- Esto significa que los datos est√°n distribuidos uniformemente alrededor del centro.

#### üìà Distribuci√≥n Sesgada a la Derecha (Sesgo Positivo)
- La cola de la distribuci√≥n se extiende hacia la derecha.
- La **media** es mayor que la **mediana**.
- Esto significa que hay m√°s valores bajos y pocos valores muy altos.

### üìà Imagen de Distribuciones con Media y Mediana

![Distribuciones Sesgadas con Media y Mediana](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20media%20y%20mediana.png)

Este gr√°fico muestra c√≥mo se ubican la media y la mediana en distribuciones sesgadas a la izquierda, normales y sesgadas a la derecha, y ayuda a entender el significado de la relaci√≥n entre la media y la mediana en cada caso.
---
## üèÅ **Conclusi√≥n** üèÅ

La estad√≠stica inferencial es una herramienta poderosa que permite tomar decisiones informadas y hacer predicciones basadas en datos muestrales. Es fundamental comprender los conceptos de hip√≥tesis, intervalos de confianza y errores para interpretar correctamente los resultados.

Con estos conocimientos, ahora tienes las herramientas necesarias para comprender y aplicar conceptos de estad√≠stica inferencial, permitiendo hacer inferencias sobre poblaciones a partir de muestras, realizar pruebas de hip√≥tesis y calcular intervalos de confianza. ¬°Contin√∫a practicando y experimentando con diferentes tipos de an√°lisis para mejorar tus habilidades en estad√≠stica inferencial!



