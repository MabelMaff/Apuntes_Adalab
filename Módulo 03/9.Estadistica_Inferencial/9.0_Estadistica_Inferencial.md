# 🧙‍♀️ **Estadística Inferencial** 🧙‍♀️ 

---

## 🔍 **Resumen de la Estadística Inferencial** 🔍

La estadística inferencial permite hacer generalizaciones sobre una población basándose en los datos obtenidos de una muestra. A diferencia de la estadística descriptiva, que se enfoca en describir los datos, la inferencial se centra en hacer predicciones y pruebas de hipótesis.

---

### 📈 **¿Qué diferencia hay entre estadística descriptiva y estadística inferencial?** 📈

1. **Estadística Descriptiva:** 📋  
   Se utiliza para describir y resumir los datos de una muestra mediante gráficos, tablas y medidas de resumen como la media, mediana y desviación estándar.

2. **Estadística Inferencial:** 📊  
   Se utiliza para hacer inferencias sobre una población a partir de una muestra, utilizando métodos como intervalos de confianza y pruebas de hipótesis.

---

### 📚 **Conceptos de Población y Muestra** 📚

1. **Población:** 🌍  
   Es el conjunto completo de todos los elementos que estamos interesados en estudiar.

2. **Muestra:** 📊  
   Es un subconjunto de la población que se selecciona para el estudio. Debe ser representativa para que las conclusiones sean válidas.

3. **Diferencia entre Población y Muestra:** 🔍  
   La población incluye todos los elementos posibles de estudio, mientras que la muestra es solo una parte seleccionada de la población.

---

### 📉 **Distribución de la Muestra** 📉

La distribución de la muestra describe cómo se distribuyen los valores de la muestra y se utiliza para hacer inferencias sobre la población.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
muestra = np.random.normal(loc=0, scale=1, size=1000)

# Visualizar la distribución de la muestra
plt.figure(figsize=(10, 6))
sns.histplot(muestra, kde=True, color='blue')
plt.title('Distribución de la Muestra')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_de_la_Muestra.png")
plt.show()
```

![Distribución de la Muestra](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20de%20la%20Muestra.png)

---

### ⚖️ **Hipótesis Nula vs Hipótesis Alternativa** ⚖️

1. **Hipótesis Nula (H0):** ❌  
   Es una afirmación general o defecto que no hay efecto o diferencia. **Asumimos que la distribución es normal**.

2. **Hipótesis Alternativa (H1):** ✔️  
   Es lo opuesto a la hipótesis nula, indicando que hay un efecto o una diferencia significativa.**Asumimos que la distribución NO es normal**.

![Hipótesis Nula vs Hipótesis Alternativa](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Hip%C3%B3tesis%20Nula%20vs%20Hip%C3%B3tesis%20ALternativa.png)

---

### 📝 **Pasos en la Prueba de Hipótesis** 📝

1. Plantear las hipótesis nula y alternativa.
2. Seleccionar un nivel de significancia.
3. Recopilar y analizar los datos de la muestra.
4. Tomar una decisión basada en los resultados.

---

### 📏 **Intervalos de Confianza** 📏

Un intervalo de confianza proporciona un rango de valores, derivado de los datos de la muestra, que probablemente contiene el valor verdadero del parámetro de la población.

```python
import numpy as np
import scipy.stats as stats

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=1000)

# Calcular el intervalo de confianza del 95%
confianza = 0.95
media = np.mean(data)
error_estandar = stats.sem(data)
intervalo = error_estandar * stats.t.ppf((1 + confianza) / 2., len(data)-1)

intervalo_confianza = (media - intervalo, media + intervalo)
print(f"Intervalo de confianza del 95%: {intervalo_confianza}")
```

![Intervalos de Confianza](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Intervalos%20de%20Confianza.png)

[Intervalo de Confianza Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Jupyters/modulo-3-leccion-09-04-intervalo-confianza.ipynb)  

---

### ⚠️ **Error Tipo I y Tipo II** ⚠️

1. **Error Tipo I:** ❌  
   Rechazar la hipótesis nula cuando es verdadera.

2. **Error Tipo II:** ❌  
   No rechazar la hipótesis nula cuando es falsa.

![Errores Tipo I y Tipo II](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Error%20Tipo%20I%20y%20Error%20Tipo%20II.png)

---

### 📐 **Distribución Muestral de la Media** 📐

La distribución de la media muestral se utiliza para entender cómo varía la media de la muestra y se aproxima a la distribución normal según el Teorema Central del Límite.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
muestras = [np.random.normal(loc=0, scale=1, size=30) for _ in range(1000)]
medias_muestrales = [np.mean(muestra) for muestra in muestras]

# Visualizar la distribución de la media muestral
plt.figure(figsize=(10, 6))
sns.histplot(medias_muestrales, kde=True, color='green')
plt.title('Distribución Muestral de la Media')
plt.xlabel('Media Muestral')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Muestral_de_la_Media.png")
plt.show()
```

![Distribución Muestral de la Media](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20Muestral%20de%20la%20Media.png)

---

### 🔍 **Pruebas de Hipótesis** 🔍

Las pruebas de hipótesis son procedimientos que permiten decidir si los datos de la muestra proporcionan suficiente evidencia para rechazar la hipótesis nula.

[Prueba de Hipótesis Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Jupyters/modulo-3-leccion-09-05-prueba-hipotesis.ipynb)

---

### 📑 **Tipos de Pruebas** 📑

1. **Prueba t de Student:** 🧮  
   Utilizada para comparar las medias de dos grupos independientes.

```python
import numpy as np
from scipy.stats import ttest_ind

# Generar datos de ejemplo
np.random.seed(0)
grupo1 = np.random.normal(loc=0, scale=1, size=100)
grupo2 = np.random.normal(loc=1, scale=1, size=100)

# Realizar la prueba t de Student
t_stat, p_value = ttest_ind(grupo1, grupo2)
print(f"t-statistic: {t_stat}, p-value: {p_value}")
```

2. **Prueba Z:** 🧮  
   Utilizada cuando el tamaño de la muestra es grande y la varianza es conocida.

```python
import numpy as np
from statsmodels.stats.weightstats import ztest

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=1000)

# Realizar la prueba Z
z_stat, p_value = ztest(data)
print(f"z-statistic: {z_stat}, p-value: {p_value}")
```

3. **Pruebas no paramétricas:** 📏  
   Utilizadas cuando no se cumplen las suposiciones de las pruebas paramétricas.

```python
import numpy as np
from scipy.stats import mannwhitneyu

# Generar datos de ejemplo
np.random.seed(0)
grupo1 = np.random.normal(loc=0, scale=1, size=100)
grupo2 = np.random.normal(loc=1, scale=1, size=100)

# Realizar la prueba de Mann-Whitney
u_stat, p_value = mannwhitneyu(grupo1, grupo2)
print(f"U-statistic: {u_stat}, p-value: {p_value}")
```

---

### 📏 **Distribuciones: Normal, Uniforme y Exponencial** 📏

#### **Distribución Normal o Gaussiana** 📈

La distribución normal, también conocida como distribución gaussiana, es una de las distribuciones de probabilidad más importantes en estadística. Se caracteriza por tener una forma de campana y está completamente definida por su media (μ) y su desviación estándar (σ).

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_normales = np.random.normal(loc=0, scale=1, size=1000)

# Visualizar la distribución normal
plt.figure(figsize=(10, 6))
sns.histplot(datos_normales, kde=True, color='purple')
plt.title('Distribución Normal')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Normal.png")
plt.show()
```
Claro, aquí tienes un ejemplo de cómo se puede aplicar la distribución normal:

### Ejemplo de Distribución Normal

#### Problema:
Supongamos que las alturas de los hombres adultos en una población siguen una distribución normal con una media (\(\mu\)) de 175 cm y una desviación estándar (\(\sigma\)) de 10 cm. Queremos calcular la probabilidad de que un hombre elegido al azar tenga una altura entre 165 cm y 185 cm.

#### Solución:
En una distribución normal, calculamos la probabilidad de un intervalo usando la función de distribución acumulativa (CDF). Sin embargo, para simplificar el cálculo, podemos usar la tabla Z o una calculadora de distribución normal estándar.

Primero, convertimos las alturas a valores Z:

\[ Z = \frac{X - \mu}{\sigma} \]

Para \( X = 165 \) cm:

\[ Z_{165} = \frac{165 - 175}{10} = \frac{-10}{10} = -1 \]

Para \( X = 185 \) cm:

\[ Z_{185} = \frac{185 - 175}{10} = \frac{10}{10} = 1 \]

Usando una tabla Z o una calculadora de distribución normal, encontramos las probabilidades correspondientes a estos valores Z:

- La probabilidad de \( Z \leq -1 \) es aproximadamente 0.1587.
- La probabilidad de \( Z \leq 1 \) es aproximadamente 0.8413.

Para encontrar la probabilidad de que \( X \) esté entre 165 cm y 185 cm, restamos estas probabilidades:

\[ P(165 \leq X \leq 185) = P(Z \leq 1) - P(Z \leq -1) \]
\[ P(165 \leq X \leq 185) = 0.8413 - 0.1587 = 0.6826 \]

Por lo tanto, la probabilidad de que un hombre elegido al azar tenga una altura entre 165 cm y 185 cm es aproximadamente 0.6826, o 68.26%.

[Distribución Normal Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

### 🔝 Test de Kolmogorov-Smirnov y Test de Shapiro-Wilk

Los tests de Kolmogorov-Smirnov y Shapiro-Wilk son pruebas estadísticas utilizadas para determinar si una muestra sigue una distribución normal. A continuación se presentan ejemplos de cómo utilizar estos tests con Python.

#### Código Python para Test de Kolmogorov-Smirnov y Test de Shapiro-Wilk:

```python
import numpy as np
from scipy.stats import kstest, shapiro

# Generar datos normales
np.random.seed(42)
datos_normal = np.random.normal(loc=0, scale=1, size=1000)

# Test de Kolmogorov-Smirnov
p_value_k = kstest(datos_normal, "norm").pvalue
print(f"P-valor del test de Kolmogorov-Smirnov: {p_value_k}")

# Test de Shapiro-Wilk
p_value_s = shapiro(datos_normal).pvalue
print(f"P-valor del test de Shapiro-Wilk: {p_value_s}")

```

### Explicación

#### 📉 Test de Kolmogorov-Smirnov
- Este test compara la muestra con una distribución de referencia (en este caso, la normal).
- La **estadística** mide la distancia máxima entre la función de distribución acumulativa de la muestra y la de la distribución de referencia.
- Un **p-valor** alto indica que no se puede rechazar la hipótesis nula de que la muestra sigue la distribución de referencia.
- **Se utiliza para muestras más grandes (más de 500).**

#### 📈 Test de Shapiro-Wilk
- Este test evalúa si una muestra sigue una distribución normal.
- La **estadística** se basa en la correlación entre los datos y los valores esperados de una distribución normal.
- Un **p-valor** alto indica que no se puede rechazar la hipótesis nula de que la muestra sigue una distribución normal.
- **Se utiliza para muestras más pequeñas (menos de 500).**
  
#### Resultados 

```plaintext
P-valor del test de Kolmogorov-Smirnov: 0.6180
P-valor del test de Shapiro-Wilk: 0.5911
```
---

#### **Distribución Uniforme** 📏

Una distribución uniforme es un tipo de distribución de probabilidad en la que todos los valores posibles tienen la misma probabilidad de ocurrir.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_uniformes = np.random.uniform(low=0, high=1, size=1000)

# Visualizar la distribución uniforme
plt.figure(figsize=(10, 6))
sns.histplot(datos_uniformes, kde=True, color='orange')
plt.title('Distribución Uniforme')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Uniforme.png")
plt.show()
```
### Ejemplo de Distribución Uniforme

#### Problema:
Supongamos que un reloj digital muestra minutos del 00 al 59. Queremos calcular la probabilidad de que cuando miramos el reloj, los minutos mostrados sean entre 15 y 30.

#### Solución:
En una distribución uniforme continua, cada valor dentro del rango es igualmente probable. La función de densidad de probabilidad para una distribución uniforme continua está definida como:

\[ f(x) = \frac{1}{b-a} \]

donde:
- \( a \) y \( b \) son los límites inferior y superior del intervalo.

En este caso, \( a = 0 \) y \( b = 59 \).

La probabilidad de que el valor esté entre 15 y 30 se puede calcular como el área bajo la curva de densidad de probabilidad en ese intervalo. Esto es simplemente la longitud del intervalo dividido por la longitud total del rango.

\[ P(15 \leq X \leq 30) = \frac{30 - 15}{59 - 0} = \frac{15}{59} \]

Calculamos la probabilidad:

\[ P(15 \leq X \leq 30) = \frac{15}{59} \approx 0.254 \]

Por lo tanto, la probabilidad de que los minutos mostrados en el reloj estén entre 15 y 30 es aproximadamente 0.254, o 25.4%.

[Distribución Uniforme Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

---

#### **Distribución Exponencial** 📈

La distribución exponencial es una distribución de probabilidad que describe **el tiempo entre eventos sucesivos e independientes en un proceso**.

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
datos_exponenciales = np.random.exponential(scale=1, size=1000)

# Visualizar la distribución exponencial
plt.figure(figsize=(10, 6))
sns.histplot(datos_exponenciales, kde=True, color='green')
plt.title('Distribución Exponencial')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.savefig("/mnt/data/Distribucion_Exponencial.png")
plt.show()
```
Claro, aquí tienes un ejemplo de cómo se puede aplicar la distribución exponencial:

### Ejemplo de Distribución Exponencial

#### Problema:
Supongamos que el tiempo que una persona espera en una cola de banco sigue una distribución exponencial con una tasa promedio (\(\lambda\)) de 2 clientes por minuto. Queremos calcular la probabilidad de que una persona espere menos de 1 minuto en la cola.

#### Solución:
En una distribución exponencial, la función de densidad de probabilidad está definida como:

\[ f(x; \lambda) = \lambda e^{-\lambda x} \]

donde:
- \( x \) es el tiempo de espera.
- \( \lambda \) es la tasa promedio de ocurrencia de eventos.

La función de distribución acumulativa (CDF) para una distribución exponencial, que nos da la probabilidad de que el tiempo de espera sea menor o igual a un cierto valor \( x \), está definida como:

\[ F(x; \lambda) = 1 - e^{-\lambda x} \]

Para calcular la probabilidad de que una persona espere menos de 1 minuto:

\[ P(X < 1) = 1 - e^{-\lambda \cdot 1} = 1 - e^{-2 \cdot 1} \]

Calculamos el valor:

\[ P(X < 1) = 1 - e^{-2} \approx 1 - 0.1353 = 0.8647 \]

Por lo tanto, la probabilidad de que una persona espere menos de 1 minuto en la cola es aproximadamente 0.8647, o 86.47%.

[Distribución Exponencial Jupyter Notebook](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuciones.png)

---

### **Distribución de Poisson** 🥛

Es una distribución de probabilidad discreta que describe **el número de eventos que ocurren en un intervalo de tiempo o espacio fijo**, conociendo la tasa promedio de ocurrencia de esos eventos. Es especialmente útil para modelar eventos raros o inusuales. La función de probabilidad de una distribución de Poisson se define como:

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

donde:
- \( k \) es el número de eventos (0, 1, 2, ...).
- \( \lambda \) es la tasa promedio de ocurrencia de eventos por intervalo (también conocido como el parámetro de Poisson).
- \( e \) es la base del logaritmo natural (aproximadamente igual a 2.71828).

### Ejemplo de Distribución de Poisson

#### Problema:
Supongamos que una central de llamadas recibe en promedio 5 llamadas por minuto. Queremos calcular la probabilidad de que la central reciba exactamente 7 llamadas en un minuto.

#### Solución:
Usamos la fórmula de la distribución de Poisson:

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

donde:
- \( \lambda = 5 \) (tasa promedio de llamadas por minuto)
- \( k = 7 \) (número de llamadas que queremos calcular la probabilidad)

Reemplazamos estos valores en la fórmula:

\[ P(X = 7) = \frac{5^7 e^{-5}}{7!} \]

Calculamos los valores:

\[ 5^7 = 78125 \]
\[ e^{-5} \approx 0.00674 \]
\[ 7! = 5040 \]

Entonces:

\[ P(X = 7) = \frac{78125 \times 0.00674}{5040} \approx 0.104 \]

Por lo tanto, la probabilidad de recibir exactamente 7 llamadas en un minuto es aproximadamente 0.104, o 10.4%.

![Distribución de Poisson](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Poisson.png)

---

### Tipos de Sesgo en Distribuciones 💹

El **sesgo en las distribuciones de datos** se refiere a la asimetría en la distribución de datos en relación con su media. Existen tres tipos principales de sesgo en las distribuciones de datos:

1. **👈 Sesgo a la Izquierda (Negativo):**
   - La cola de la distribución se extiende más hacia la izquierda.
   - La mayoría de los datos están concentrados en el lado derecho de la media.
   - Ejemplo: Ingresos de una población donde hay pocos ingresos muy bajos y muchos ingresos medios y altos.

2. **〰 Distribución Simétrica (Normal):**
   - La distribución no está sesgada ni a la izquierda ni a la derecha.
   - La media, la mediana y la moda son iguales.
   - Ejemplo: Alturas de una población donde la mayoría de las personas tienen una altura cercana a la media.

3. **👉 Sesgo a la Derecha (Positivo):**
   - La cola de la distribución se extiende más hacia la derecha.
   - La mayoría de los datos están concentrados en el lado izquierdo de la media.
   - Ejemplo: Ingresos de una población donde hay muchos ingresos bajos y pocos ingresos muy altos.

   ![Distribución Sesgada a la Derecha](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20media%20y%20mediana.png)

### 🔀 Media y Mediana en Distribuciones Sesgadas 🔀

La **media** y la **mediana** son medidas de tendencia central que se utilizan para describir la distribución de un conjunto de datos. La relación entre la media y la mediana puede proporcionar información sobre la asimetría de la distribución de los datos (sesgo).

### Generación de Datos y Gráficos

Vamos a generar datos para tres tipos de distribuciones y ubicar la media y la mediana en cada una.

#### Código Python:

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)

# Sesgo a la izquierda (Negativo)
left_skewed_data = np.random.beta(a=2, b=5, size=1000) * 10
left_mean = np.mean(left_skewed_data)
left_median = np.median(left_skewed_data)

# Distribución Normal (Simétrica)
normal_data = np.random.normal(loc=5, scale=1, size=1000)
normal_mean = np.mean(normal_data)
normal_median = np.median(normal_data)

# Sesgo a la derecha (Positivo)
right_skewed_data = np.random.beta(a=5, b=2, size=1000) * 10
right_mean = np.mean(right_skewed_data)
right_median = np.median(right_skewed_data)

# Crear histogramas para cada distribución
fig, axes = plt.subplots(3, 1, figsize=(8, 12))

# Distribución Sesgada a la Izquierda
axes[0].hist(left_skewed_data, bins=30, color='blue', alpha=0.7, edgecolor='black')
axes[0].axvline(left_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {left_mean:.2f}')
axes[0].axvline(left_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {left_median:.2f}')
axes[0].set_title('Distribución Sesgada a la Izquierda (Sesgo Negativo)')
axes[0].set_xlabel('Valor')
axes[0].set_ylabel('Frecuencia')
axes[0].legend()

# Distribución Normal
axes[1].hist(normal_data, bins=30, color='green', alpha=0.7, edgecolor='black')
axes[1].axvline(normal_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {normal_mean:.2f}')
axes[1].axvline(normal_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {normal_median:.2f}')
axes[1].set_title('Distribución Normal (Simétrica)')
axes[1].set_xlabel('Valor')
axes[1].set_ylabel('Frecuencia')
axes[1].legend()

# Distribución Sesgada a la Derecha
axes[2].hist(right_skewed_data, bins=30, color='red', alpha=0.7, edgecolor='black')
axes[2].axvline(right_mean, color='red', linestyle='dashed', linewidth=2, label=f'Media: {right_mean:.2f}')
axes[2].axvline(right_median, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {right_median:.2f}')
axes[2].set_title('Distribución Sesgada a la Derecha (Sesgo Positivo)')
axes[2].set_xlabel('Valor')
axes[2].set_ylabel('Frecuencia')
axes[2].legend()

# Ajustar el diseño
plt.tight_layout()

plt.show()
```

### Explicación

#### 📉 Distribución Sesgada a la Izquierda (Sesgo Negativo)
- La cola de la distribución se extiende hacia la izquierda.
- La **media** es menor que la **mediana**.
- Esto significa que hay más valores altos y pocos valores muy bajos.

#### 🔄 Distribución Normal (Simétrica)
- La distribución no está sesgada ni a la izquierda ni a la derecha.
- La **media** y la **mediana** son iguales.
- Esto significa que los datos están distribuidos uniformemente alrededor del centro.

#### 📈 Distribución Sesgada a la Derecha (Sesgo Positivo)
- La cola de la distribución se extiende hacia la derecha.
- La **media** es mayor que la **mediana**.
- Esto significa que hay más valores bajos y pocos valores muy altos.

### 📈 Imagen de Distribuciones con Media y Mediana

![Distribuciones Sesgadas con Media y Mediana](https://github.com/MabelMaff/Apuntes_Adalab/blob/main/M%C3%B3dulo%2003/9.Estadistica_Inferencial/Imagenes/Distribuci%C3%B3n%20media%20y%20mediana.png)

Este gráfico muestra cómo se ubican la media y la mediana en distribuciones sesgadas a la izquierda, normales y sesgadas a la derecha, y ayuda a entender el significado de la relación entre la media y la mediana en cada caso.
---
### 🏁 **Conclusión** 🏁

La estadística inferencial es una herramienta poderosa que permite tomar decisiones informadas y hacer predicciones basadas en datos muestrales. Es fundamental comprender los conceptos de hipótesis, intervalos de confianza y errores para interpretar correctamente los resultados.

Con estos conocimientos, ahora tienes las herramientas necesarias para comprender y aplicar conceptos de estadística inferencial, permitiendo hacer inferencias sobre poblaciones a partir de muestras, realizar pruebas de hipótesis y calcular intervalos de confianza. ¡Continúa practicando y experimentando con diferentes tipos de análisis para mejorar tus habilidades en estadística inferencial!



